name: OpenRouter AI Review

on:
  pull_request:
    types: [opened, synchronize]
  push:
    branches: [main]

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  ai-review:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup mise
      uses: jdx/mise-action@v2
      with:
        cache: true
        experimental: true

    - name: Review with OpenRouter
      if: github.event_name == 'pull_request'
      env:
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      run: |
        # Get diff
        git diff origin/main...HEAD > pr-diff.txt
        
        # Review using OpenRouter with Gemini Flash (cheapest)
        review=$(curl -s https://openrouter.ai/api/v1/chat/completions \
          -H "Authorization: Bearer $OPENROUTER_API_KEY" \
          -H "Content-Type: application/json" \
          -H "HTTP-Referer: https://github.com/mikkihugo/claude-yolt" \
          -d '{
            "model": "google/gemini-flash-1.5-8b",
            "messages": [
              {
                "role": "system",
                "content": "You are reviewing claude-yolt, a tool that fixes process explosion bugs in Claude CLI."
              },
              {
                "role": "user",
                "content": "Review this PR diff for:\n1. Security issues\n2. Process handling bugs\n3. Memory leaks\n4. Performance issues\n\nDiff:\n'"$(cat pr-diff.txt | head -2000 | jq -Rs .)"'"
              }
            ],
            "temperature": 0.3,
            "max_tokens": 1000
          }' | jq -r '.choices[0].message.content')
        
        # Post review
        gh pr comment ${{ github.event.pull_request.number }} --body "## ðŸ¤– OpenRouter AI Review
        
        Model: \`google/gemini-flash-1.5-8b\`
        
        $review
        
        ---
        *Powered by OpenRouter*"
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Analyze with Google AI
      env:
        GOOGLE_AI_KEY: ${{ secrets.GOOGLE_AI_KEY }}
      run: |
        # Alternative: Direct Google AI (Gemini)
        if [ -n "$GOOGLE_AI_KEY" ]; then
          analysis=$(curl -s "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=$GOOGLE_AI_KEY" \
            -H 'Content-Type: application/json' \
            -d '{
              "contents": [{
                "parts": [{
                  "text": "Analyze claude-yolt for bugs:\n\n'"$(cat lib/process-interceptor.js | head -500 | jq -Rs .)"'"
                }]
              }],
              "generationConfig": {
                "temperature": 0.3,
                "maxOutputTokens": 1000
              }
            }' | jq -r '.candidates[0].content.parts[0].text')
          
          echo "## Google AI Analysis"
          echo "$analysis"
        fi

  benchmark-models:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        model: [
          "google/gemini-flash-1.5-8b",      # $0.000015/1k
          "meta-llama/llama-3.2-3b-instruct", # $0.00006/1k
          "qwen/qwen-2.5-7b-instruct",        # $0.00035/1k
        ]
    steps:
    - uses: actions/checkout@v4

    - name: Test Model Response
      env:
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      run: |
        echo "Testing model: ${{ matrix.model }}"
        
        response=$(curl -s https://openrouter.ai/api/v1/chat/completions \
          -H "Authorization: Bearer $OPENROUTER_API_KEY" \
          -H "Content-Type: application/json" \
          -d '{
            "model": "${{ matrix.model }}",
            "messages": [{
              "role": "user",
              "content": "Find bugs in: activeProcesses.set(pid, processInfo);"
            }],
            "temperature": 0.1,
            "max_tokens": 200
          }' | jq -r '.choices[0].message.content' || echo "Model failed")
        
        echo "Response: $response"